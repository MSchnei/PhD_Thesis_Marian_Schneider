\chapter{General discussion}

\clearpage{\thispagestyle{empty}\cleardoublepage}

\section{Overview}
The goal of this thesis was to leverage the new opportunities in functional magnetic resonance imaging (fMRI) research afforded by higher field strength to study the neural correlates of visual conscious content in humans (content-specific NCC). In order to achieve this goal, we first saw the need to develop a tool that aids tissue class segmentation of ultra-high field (UHF) images (Chapter 2). We then performed two high-field high-resolution fMRI experiments to clarify how representations in topographically organized cortical structures are related to the perception of apparent motion (Chapter 3) and apparent position (Chapter 4). After summarizing the results of each study, the presented work will be contextualized by relating it to the conceptual framework proposed by \cite{DeGraaf2012} and by highlighting common considerations that motivated and guided the experimental design of all studies. Subsequently, limitations of the presented studies will be discussed and taken as motivation to outline a new vision for UHF fMRI and consciousness research.

\section{Summary}
Neuroimaging at UHF offers increased sensitivity and specificity. Yet these advantages can only take full effect if certain challenges are appropriately addressed - including co-registration of anatomical and functional images with partial coverage, geometric distortions, registration of functional images across scanning sessions and tissue class segmentation. While there are solutions or adequate workarounds for most of these issues, we found tissue class segmentation at UHF to constitute such a severe bottleneck that we decided to tackle this issue first in the form of a new tool. In Chapter 2, we proposed that 2D histograms offer a suitable representation of 3D anatomical images that allows for efficient editing of segmentation images. In particular, motivated by theoretical expectations, we expected non-brain voxels to become separable from brain voxels in the 2D space represented by image intensity and gradient magnitude. Based on previous results, we suggested that separation could either be obtained using appropriate widgets with expert knowledge or using more automated techniques such as normalized graph cuts. We then created our own, openly accessible implementation of the proposed methods and two annotated 7 Tesla MRI data sets for validation. We demonstrated that our method improves cortical grey matter definitions when used as an additional post-processing step to existing segmentation algorithms and frees a considerable amount of researcher time that would otherwise need to be spent on manual corrections. 

Equipped with this new tool, we went on, in Chapter 3, to clarify how responses in columnar clusters of the human motion complex (hMT+) relate to the conscious experience of a specific visual motion axis (hereafter called "motion quartet study"). Leveraging the increased sensitivity of UHF, we first mapped out distinct, fine-grained clusters that either preferred horizontal or vertical motion. We then measured their response modulations during ambiguous stimulation with the bistable motion quartet. We found that when participants indicated the conscious percept of horizontal motion the response amplitude increased in the "horizontal" cluster and decreased in the "vertical" cluster, while we found the reverse pattern during vertical motion. Finally, we also demonstrated that these clusters were organized in a columnar fashion such that preferences for vertical or horizontal motion were stable in the direction of cortical depth and changed when moving along the cortical surface. These results support the idea that hMT+ makes up part of the content-specific NCC for visual motion and, more importantly, extend this idea by demonstrating involvement of specific horizontal and vertical columnar clusters in tracking conscious experience of a particular motion axis.

While this study imposed important constraints the location of content-specific NCC, it did not offer a strong constraint on mechanisms that link cortical activity to conscious visual perception. In Chapter 4, we therefore explored the ability of the population receptive field (pRF) mapping paradigm to connect responses in early and mid-level visual cortex to the perceived position of visual stimuli (hereafter called "motion-dependent pRF study"). We first identified stimulus contrast as an important factor that influences the strength of motion-induced position shifts. We observed that at high stimulus contrast, when sufficient sensory evidence is available, little to no perceptual displacements occur, while at low stimulus contrast, when signal uncertainty is increased, substantial perceptual displacements occur. Correspondingly, we found that pRF centers were substantially shifted against the direction of motion for low-contrast, but not high-contrast, stimuli. Based on these observations, we proposed a model that links pRF estimates to perceived stimulus position. This model is based on the idea that early visual areas send shifted population codes in response to motion stimuli that bias the conscious percept of stimulus position in the direction of motion.

\section{Past and current context}
In this section, we will first discuss how the obtained results can be interpreted and what they imply for the search of content-specific NCC. We will then highlight two common threads that run through the presented research. Specifically, we will argue that the studies can be understood as a reaction to both the earlier introduction of multivariate pattern analysis (MVPA) techniques and the more recent debate about reproducibility.

\subsection{Prerequisites, substrates and consequences}
De Graaf and colleagues \parencite*{DeGraaf2012} proposed a conceptual distinction for NCC that offers a framework for interpreting the results obtained in this thesis. The authors pointed out that an NNC may fall into one of three distinct categories: It may be a prerequisite, a consequence, or the actual substrate of a conscious experience. Neural prerequisites are neural events or processes that are necessary for a particular conscious experience; yet they are not themselves the "neural instantiation" of that conscious experience \parencite{DeGraaf2012}. Examples of neural prerequisites are neural events associated with wakefulness, arousal and attention. If these events did not occur, a conscious experience would not occur. By contrast, neural consequences are the result of neural events underlying the conscious experience. There may be content-specific consequences (when the conscious experience of a rose gives rise to associative responses such as the memory of our grandmother who grew roses in her garden) and content-invariant consequences (neural events that follow any kind of conscious experience) \parencite{DeGraaf2012}. Thus, although prerequisites and consequences by definition always co-occur with a conscious experience, they do not directly underlie its subjective phenomenal content - as the neural substrate does. Only the neural substrate is the neural state that is directly underlying the experience and is neither a result nor a precondition for a specific conscious percept.

The conceptual distinctions proposed by de Graaf et al. are useful for interpreting the empirical results presented in this thesis. Reversely, our findings have implications for the strategies suggested to dissociate prerequisites, substrates and consequences of conscious experience from each other. With regard to the findings presented in Chapter 3, it is difficult to determine with certainty whether the observed response modulations in the vertical or horizontal clusters are prerequisites, substrates or consequences. Given that the identified NCC are content-specific and applying Occam's razor, however, we propose that the observed response modulations are neural \textit{substrates} for the experience of a specific visual axis of motion. In this interpretation, we benefit from the increased explanatory power that comes with the research approach of content-specific NCC, as opposed to general NCC (see Chapter 1). After all, in an independent analysis step, we first mapped out the representational content for hMT+ and showed that its states represented horizontal and vertical visual motion. One would need to introduce additional assumptions in order to explain that these states also correlated with conscious content of exactly horizontal and vertical visual motion if they are just general prerequisites or consequences. This would not be parsimonious and we thus favour the hypothesis that the columnar clusters identified in Chapter 3 are neural substrates. However, as pointed out by De Graaf et al. \parencite*{DeGraaf2012} and as shown below, content-specific NCC are not always neural substrates since sometimes neural prerequisites and consequences can also be content-specific.

In the context of the study presented in Chapter 3, it also becomes apparent that one of the strategies suggested by \cite{DeGraaf2012} for dissociating neural prerequisites/consequences from substrates might be problematic, at least in the context of traditional macroscopic fMRI studies. The authors proposed that brain areas which activate during unconscious perception should be discarded as content-specific candidates for substrates of conscious experience. However, given that we demonstrated that correlation with conscious motion perception can be restricted to fine-grained clusters within an area, it is conceivable that only part of the area (such as hMT+) is a substrate of conscious experience. It is possible that unconscious processes correlate with neural events in some sub-parts of hMT+ that are unrelated to conscious processing. Using macroscopic fMRI studies it is difficult to distinguish different sub-parts of an area since signals are often averaged across all voxels in an area or spatial smoothing is applied to increase statistical power (or both). We therefore caution against discarding an area as a neural substrate candidate all together simply based on finding activation during unconscious processes in a macroscopic fMRI study.

Regarding the findings presented in Chapter 4, we suggest to interpret the observed pRF displacements for low-contrast stimuli as neural prerequisites for conscious position perception. Furthermore, if the hypothesized mechanism for linking pRF shifts to perceptual displacements is correct, then the pRF shifts should be considered \textit{content-specific} neural prerequisites. To elaborate, the observed shifts in early visual areas cannot be the neural substrate of perceived position because the neural and perceptual displacements are in opposite directions. Therefore, the content represented in the neural system does not match that represented in consciousness. The identified NCCs, although only prerequisites, can still be content-specific if, as we have proposed, the shifted population code they produce is read-out by higher-order areas. Based on the population-level code higher-order areas misattribute the stimulus position (by a particular) amount such that neural representation of position and the perceived position of the stimulus now match. If this (speculative) scenario is correct, then these higher-order areas should be considered the neural substrate of conscious position perception and the early visual areas their content-specific prerequisite.

The analysis conducted in Chapter 4 also exemplifies a new strategy for dissociating neural prerequisites from substrates. De Graaf and colleagues \parencite*{DeGraaf2012} suggested that if neural events temporally precede a given conscious experience, they cannot be substrates but must be prerequisites. By analogy, we would propose that, in addition to temporal precedence, there is also mechanistic precedence that allows us to tell prerequisites from substrates. A mechanistic explanation always specifies a sequence of steps in order to account for a given phenomenon. In Chapter 4, for example, the proposed mechanism links the pRF shifts in early visual cortex to perceptual displacements in position via a number of steps. Since the pRF shifts in early visual cortex mechanistically precede the read-out by higher-order areas and the corresponding conscious experience, they cannot be neural substrates but must be prerequisites. Note that mechanistic precedence here implies temporal precedence - with the difference that temporal precedence can only be established empirically, while mechanistic precedence can be derived from mechanistic model assumptions.

\subsection{Historical context: Reaction to mvpa studies}
In several ways, the studies presented in this thesis are a reaction to the introduction and wide-spread use of MVPA techniques for the analysis of fMRI data since the early years of the millennium \parencite{Haxby2014}. MVPA is a powerful analysis method and has several advantages compared to classical activation-based analysis methods \parencite{Mur2009}. MVPA is more sensitive than univariate GLM analyses because the response of many voxels is jointly analyzed. This means that MVPA is able to classify patterns of brain activity into distinct experimental stimuli, tasks or states even if average signal change in a voxel or ROI does not differ across conditions. Furthermore, MVPA can offer an intuitive decoding of brain states that can be beneficially combined with real-time fMRI methods \parencite{LaConte2007}.

However, the interpretation of MVPA results is fraught with ambiguities \parencite{Bartels2008, Logothetis2008, Wang2014, Naselaris2015a}. Naselaris and Kay \parencite*{Naselaris2015a} identified three types of ambiguity for MVPA - geometric, spatial and representational ambiguity. Geometric ambiguity refers to the fact that, once MVPA has identified a difference between two experimental conditions, it is unclear whether the corresponding brain activity patterns, represented in the analysis as multivariate vectors, differed in their orientation or in their length. It is considered the most benign type of ambiguity since it can be resolved via additional activation analyses. Spatial ambiguity refers to the limitation that successful classification of experimental conditions does not offer any information about the underlying spatial organization and structure that may have supported classification - such as, for example, topographic organization, columnar, or laminar structures (but see \cite{Kriegeskorte2006}). Lastly, representational ambiguity refers to the problem that MVPA cannot identify the different sources of variation that might have driven classification performance.

The problems of spatial and representational ambiguity are illustrated by the debate surrounding hyperacuity or subvoxel resolution that MVPA was thought to confer to fMRI. Initially, the successful categorization with MVPA of stimulus orientation \parencite{Haynes2005, Kamitani2005} and motion direction \parencite{Kamitani2006} in early visual areas was assumed to be driven by small differences in responses at the level of different orientation or direction-of-motion columns even though the spatial resolution employed in these studies was too low to resolve columnar structures directly. Yet later studies convincingly demonstrated that the reported response pattern differences were driven by large-scale spatial biases such as activity elicited by the edge of an oriented grating \parencite{Freeman2011, Carlson2014, Roth2018} or the trailing edge of a motion stimulus \parencite{Wang2014}. These examples caution against inferring any particular spatial organization from response differences identified in MVPA and highlight that successful decoding of a stimulus feature does not imply that this feature is actually represented or encoded in the measured population.

In the present work, the combination of high-resolution imaging with explicit models of representation \parencite{Naselaris2015a} allowed us to resolve (some of) this spatial and representational ambiguity. In the case of the motion quartet study we combined sub-millimeter resolution imaging with the simplest possible encoding model \parencite{Naselaris2011}, a GLM with only two predictors, to encode axis of motion. This approach allowed us to demonstrate the existence of two distinct neural populations representing different motion axes and to show their spatial columnar organization. Although previous MVPA studies had found small activation differences between perceptual states related to different motion directions \parencite{Kamitani2006, Brouwer2007}, they could not make claims about the underlying spatial organization of such activation patterns \parencite{Logothetis2008, Bartels2008}.

In case of the motion-dependent pRF study we used pRF mapping, which directly encodes position in visual space as the relevant stimulus feature driving an individual voxel's response. The pRF mapping benefited from high-resolution imaging since, with decreased voxel size, the distribution of neurons contained in a voxel becomes more homogeneous in terms of their RF \parencite{DeMartino2016}. Previous studies \parencite{Fischer2011, Maus2013} found that patterns of fMRI responses in early visual areas reflected physical stimulus position while higher areas like V3a, LO or hMT+ represented the perceived position. However, due to representational ambiguity it is unclear which feature was driving the observed correlations in response patterns. Using the voxel-wise pRF model and explicitly encoding position enabled us to show that pRFs are displaced against the direction of motion under conditions of perceived position shift.

\subsection{Current context: Reaction to reproducibility debate}
The studies presented in this thesis share several experimental design strategies. Many of these common strategies can be understood by reference to the recent debate surrounding reproducibility in human neuroimaging research. Neuroimaging researchers are becoming increasingly aware of the importance of reproducibility and some have openly expressed concern that conclusions drawn from many human neuroimaging studies might not be reproducible \parencite{Poldrack2017a}. Poldrack and colleagues \parencite*{Poldrack2017a} identified several factors that can contribute to false-positive findings. These factors include low statistical power, flexibility in data analysis, insufficient study reporting, software errors and a lack of direct replication. Over the next few paragraphs, the current work will be discussed in the light of these factors in order to highlight how (some of) these problems have been addressed.

One major factor increasing the risk of false-positive findings is low statistical power. As pointed out by Poldrack et al. \parencite*{Poldrack2017a}, even detecting the large effect that results from the comparison of motor activity to rest requires a study with more than 20 subjects. In this light, the prospects for conducting a reproducible fMRI study and identifying much smaller cognitive effects appear bleak. To make things worse, UHF fMRI studies pose additional practical restrictions that prevent large sample sizes. Since the price of a single scanning session at a 7T scanner is currently in the order of several hundreds of Euros, many researchers need to content themselves with as little as 20 scanning hours per study. In addition to monetary constraints, other limitations apply. As highlighted in this thesis, automatic segmentation algorithms yield results that often do not meet the quality demands of high-resolution analyses. Consequently, many hours of manual corrections are needed per subject and tissue class segmentations become a bottleneck for studies with large sample size.

As a result of these practical limitations, the results reported in this thesis are based on a handful of individuals only. In order to alleviate concerns about power, we used several strategies. First, instead of collecting little data for many participants, we studied a few individuals in great detail by acquiring many hours of scanning for every individual (five to eight hours of MRI data per individual) \parencite{Poldrack2017b}. This approach is common in visual neuroscience and, in particular, electro-physiology studies of primate brains because the need for extensive training and eventual sacrifice of the monkeys makes large sample sizes impractical and unethical. The approach is made possible by relatively large responses in visual cortex that usually yield sufficient signal-to-noise (SNR) to study effects in individual brains. Proponents of such small-N designs point out that neural and behavioural studies usually face a trade-off between sampling and measurement error \parencite{Kolossa2018, Smith2018}. Sampling error results from variance across participants, while measurement error results from variance across different measurements in the same individual. Scarce research time can either be used to sample more subjects or to sample more data per subject. The decision to prioritize one option over the other should be made by considering which variance is expected to be higher. For the UHF high-resolution fMRI studies presented in Chapter 3 and 4, it can be argued that measurement error is more severe. On the one hand, high-spatial resolution is afforded by trading in SNR which makes high-resolution studies SNR-limited (higher measurement error). On the other hand, the visual areas studied here represent basic sensory systems which are expected to be similar across individuals (lower sampling error). For these reasons, it can be justified to prioritize data quality over data quantity \parencite{Kolossa2018}. It is important to keep in mind, however, that this approach limits inference to the studied individuals and does not allow for generalization of results to the population level. This important limitation applies to all studies presented in this thesis and, consistent with it, we did not employ and report standard group statistics and showed single-subject results instead.

A second strategy that we used to improve statistical power was to limit our analysis to ROIs that were defined using independent functional localizer data. This approach increases power by limiting the search space and reducing multiple comparisons. Fortunately, this strategy dovetails well with the standard approach for the search for NCC, outlined in Chapter 1. The NCC approach requires that data analysis is divided into two steps. Before correlation between the representations in a neural system and in consciousness can be investigated, the representational states of a neural system first need to be mapped out. Similarly, to avoid circularity \parencite{Kriegeskorte2009}, ROIs first need to be explicitly delineated based on independent data before any other statistical analysis steps can be conducted \parencite{Poldrack2017a}.

Next to low statistical power, flexibility in data analysis can also hamper reproducibility. All the findings reported in this thesis are the result of many different pre-processing and analysis steps. For each step, one particular method and set of parameters needed to be chosen out of a multitude of potential alternatives. This results in variability of observed effects across all theoretically possible analysis settings. Such variability can be substantial \parencite{Carp2012} and is problematic if the reported effect is highly dependent on a specific configuration of settings or if researchers intentionally modify the analysis settings until significant results are obtained. This analytical flexibility has been termed "researcher degrees of freedom" \parencite{Simmons2011}.

Some authors have suggested pre-registration of methods and analysis plans as the main solution to this problem \parencite{Poldrack2017a}. However, it can be argued that pre-registration unduly restricts explorative efforts, which is essential to scientific discovery, and hampers the development of novel analysis techniques. This is particularly relevant in the context of UHF studies, since harvesting the opportunities afforded by UHF is only possible after the development of appropriate analysis methods (see Chapter 1 and 2).

To reduce researcher degrees of freedoms, we instead combined several strategies throughout this thesis. First, especially for data preparation and pre-processing, we aimed to restrict ourselves to default parameters and deviation from default settings was clearly motivated and reported in the methods description. Second, we usually explored the impact of analysis settings in a single subject and, after having established an analysis pipeline, we validated analysis and results in the other subjects. Third, even after an analysis pipeline was established and the result figures for each project were created, we still systematically varied some analysis settings to check that the observed effects are robust over a wider range of settings. For example, we commonly varied the number of voxels included in a ROI to see how variable the obtained effects were (see Chapter 3) and to determine the parameter space for which the obtained results hold. Although all these strategies limit analytical flexibility, the research presented in this thesis should still be considered exploratory and further validation of the findings presented here is important.

Other obstacles to reproducibility are insufficient study reporting and software errors \parencite{Eklund2016}. Insufficient study reporting means that the methods described in a scientific paper are not enough for other researchers to redo the analyses that gave rise to the reported results and conclusions. One remedy to this problem is adherence to established reporting guidelines, such as the COBIDAS report \parencite{Nichols2017} of the Organization for Human Brain Mapping (OHBM). We tried to adhere to these guidelines throughout this thesis, where possible. However, there is an inherent conflict between the readability and reproducibility of a methods section. For example, listing all the parameters that are used for distortion correction (around 30 parameters) makes research more reproducible but would also make a manuscript entirely unreadable.

There are at least two alternative and potentially more efficient ways for communicating analysis steps, which have been used in all studies presented in this thesis. First, flow chart diagrams offer a comprehensive overview of all the relevant (pre-)processing steps of a study. It turned out that this was not only helpful to communicate the processing pipeline to other researchers but was a welcome memory aid to ourselves as well. Second, making both data and analysis code available appears to be the best solution to increase reproducibility without sacrificing readibility of the manuscript. For this, the use of services such as GitHub and Zenodo have proven very helpful. Since GitHub (and other services) combines distributed version control with a web-based hosting service, it both reduces the chance of software bugs and improves study reporting. Version control with Git enabled us to organize analysis code and to keep track of code changes. It also enabled collaborative coding efforts among co-authors. All this facilitated tracing and detecting software errors at an early stage. Since repositories are web-based, analysis code can be easily released upon publication or can be shared already during software and analysis development.

\section{Limitations and future directions}
Several limitations apply to the findings reported in this thesis that relate to experimental design, MRI methodology, analysis methodology or interpretation of our results. These limitations reflect the two big research lines that were introduced in the Introduction chapter - human neuroimaging at UHF and the search for content-specific NCC. We will start by discussing limitations that are specific to a particular study but then go on to formulate, more generally, desirable directions for future UHF fMRI and consciousness research.

\subsection{Tissue class segmentation at uhf}
We estimated that the 2D histogram method presented in Chapter 2 saves on average 7.5 hours of manual work for a whole brain cortical ribbon segmentation of a single subject \parencite{Gulban2018a}. While this is a valuable time-saver, the presented method does not entirely eliminate the need for manual corrections and even more automation of the segmentation task would be desirable. The main problem with tissue class segmentation of UHF MRI images is that most of the segmentation algorithms have been benchmarked using low-field, lower resolution data \parencite{Helms2016}. Therefore, these algorithms often do not deal well with the additional anatomical detail apparent in UHF images. A straightforward approach would be to train the same algorithms on UHF data. However, many segmentation algorithms \parencite{Ashburner2005, Bazin2014} rely on particular templates, atlases or other forms of prior information. This constitutes an important hindrance whenever new forms of data become available (for example partial acquisitions) because they might not conform to the pre-supposed shape. By contrast, a human expert can perform segmentation very flexibly and adjust to new forms of data quickly.

For these reasons, it is desirable to develop new algorithms that deploy skills akin to human perception and action. One very promising direction is the use of deep convolutional neural networks (CNN) for image segmentation. It was demonstrated that CNNs trained for image classification constitute a good model of the ventral visual pathway system for object recognition in humans \parencite{Kriegeskorte2014, Yamins2016}. Thus, there appear to be important parallels between the neural implementation for image classification in humans and CNNs. Image classification can be extended to image segmentation by not only identifying the objects in an image but also determining for every pixel in the image to which object it belongs. A convolutional network called U-net (because it takes the shape of a U) currently offers close-to-human performance in image segmentation tasks, at least for segmenting microscopic images of neuronal structures in fruit flies \parencite{Ronneberger2015} and kidneys of clawed frogs \parencite{Cicek2016}. An obvious direction for future research is the implementation of a 3D U-net for tissue class segmentation of UHF MRI images of the human brain and comparison of its performance to conventional segmentation algorithms used for this task.

\subsection{Columnar fmri and large draining veins}
One important limitation of the columnar fMRI study presented in Chapter 3 is the potential contribution of large draining veins to the reported fMRI signal. Two different types of veins should be distinguished. In the columnar and laminar fMRI literature, when authors speak of "draining veins" they frequently refer to pial veins that are located on the cortical surface. These pial veins render the signal close to the grey matter (GM) / cerebrospinal fluid (CSF) boundary less specific \parencite{Polimeni2010, Moerel2017} and are a major contributor to an increase in fMRI signal towards the superficial cortical depth levels, a finding that is very robust across many laminar fMRI studies \parencite{Ress2007, Koopmans2010, Polimeni2010, Koopmans2011, DeMartino2013, Marquardt2018}. Yet there is a second meaning to the term "draining vein" that describes ascending cortical veins which originate in deep cortical depth and, as they ascend towards the pial surface, increase in diameter due to the collection of venous blood \parencite{Duvernoy1981}. These ascending cortical veins are problematic for laminar fMRI studies since they also contribute to a cortical depth profile that is biased towards superficial cortical depths. However, these veins pose a particular problem to the interpretation of columnar fMRI studies because they usually run radially to the cortical surface, just like columns, and may mimic columnar-like neuronal activity \parencite{DeMartino2016}.

An obvious remedy to this limitation is to use sequences other than gradient echo echo planar imaging (GE EPI) that have less sensitivity to large veins. Alternative sequences that have been proposed and employed in the literature for laminar and columnar fMRI are 3D GRASE \parencite{Feinberg2008, Zimmermann2011, DeMartino2013, Kemper2015, Moerel2017} and VASO \parencite{Huber2015, Huber2017}. Uludag and colleagues \parencite*{Uludag2009} showed that spin echo (SE) sequences in particular become less macrovasculature weighted when moving to 7T. Since the 3D GRASE sequence is a combination of SE and GE elements, it is expected to be less macrovasculature weighted and thus more specific - a prediction that was supported experimentally by \cite{DeMartino2013}. The VASO sequence offers a measure of cerebral blood volume and therefore can provide higher spatial specificity \parencite{Huber2015, Huber2017}. Next to an increase in specificity, these sequences have other advantages for mesoscopic fMRI. As a result of their small spatial coverage, 3D GRASE and VASO images tend to show less geometric distortions than images acquired with GE EPI sequences, simplifying one of the major challenges for current UHF fMRI studies (see Chapter 1). Furthermore, for the VASO sequence, it is relatively straightforward, via a modification of the sequence, to generate images with sufficient white matter (WM)/GM/CSF contrast that allow for tissue class segmentation. Thus, some of the problems with building an anatomical reference (see Chapter 1) can be circumvented.

However, 3D GRASE and VASO also each have their distinct disadvantages. In particular, both sequences have very limited coverage compared to 2D or 3D GE EPI sequences \parencite{Zimmermann2011, Huber2015, Huber2017}, which poses severe restrictions on the region of interest to be studied as well as on subject motion during scanning. Furthermore, as a consequence of the reduced macrovasculature weighting, both 3D GRASE and VASO are less sensitive than 2D GE EPI (demonstrated empirically for 3D GRASE in \cite{DeMartino2013}). Unfortunately, I can fully attest to the correctness of this finding based on my own experience. To further validate the findings presented in Chapter 3, we initially also recorded data with the 3D GRASE sequence (five participants with one scanning session each). For the GE EPI data reported in Chapter 3 at least two scanning sessions were necessary to robustly observe the reported effects. However, a trend in the expected direction was already apparent after a single scanning session. This was not the case for the 3D GRASE data, and as a young researcher new to fMRI data analysis it took me the first half of my PhD to realize and comprehend that the temporal SNR of the 3D GRASE images was too low to draw valid and reliable conclusions from the data. Now, with the experience and insights gained over the years, I would record data from only one or two subjects but with four to five scanning sessions each. Such a setup would offer important validation for the claims about columnarity made in Chapter 3.

Another remedy to the limitation of ascending cortical veins could become available in the future by applying an accurate spatial deconvolution model that takes signal contribution of these veins into account \parencite{Markuerkiaga2016}. We have used such a model in a laminar fMRI study investigating contrast-dependence in V1 and V2 \parencite{Marquardt2018}. However, it is not straightforward to extend this approach to columnar fMRI studies since the deconvolution parameters will need to vary when moving along the cortical plane direction in order to account for the varying distribution of veins. Furthermore, currently the deconvolution model relies on vasculature estimates obtained from animal studies which are only available for primary visual cortex. Therefore, a challenge for the future will be to extent this model to mid-level areas (such as hMT+) and even higher-order areas for which no homologous area in non-human animal might exist. Both these problems could be addressed by developing accurate in-vivo methods for mapping out ascending cortical veins in humans \parencite{DeMartino2016}.

\subsection{Laminar contributions within a column}
For the study presented in Chapter 3, our approach was to identify distinct columnar clusters and then to test whether the average signal across all voxels in a given cluster reflected the conscious percept. We believe that this approach was an important first step and demonstrates the novel empirical opportunities offered by columnar fMRI to probe content-specific NCC in humans. However, several additional insights for perceptual processing could have been gained if we had been able to study more precisely where in a given columnar cluster the conscious percept is reflected or formed. This could be achieved by measuring distinct laminar contributions to the identified columnar clusters. Several theoretical and empirical observations suggest that this will represent a fruitful avenue for future research. We will illustrate our considerations by referring to the specific example of the motion quartet study in Chapter 3 but we believe that these points hold more generally for columnar fMRI studies probing perception.

Results from animal physiology indicate that different computational processes occur across different cortical layers \parencite{Felleman1991, Rockland1979, Markov2014}. In particular, feedback connections appear to originate from neurons mainly in deep layers (layer VI), and terminate mainly in layer I or in a combination of layers, but not in layer IV (granular layer) \parencite{Rockland1994, Salin2017}. By contrast, forward connections originate in superficial cortical layers (layer II and III) and terminate in layer IV. Inspired by these insights from animal physiology, we predict that bottom-up and lateral / top-down processes will recruit different laminar parts of a column.

In the specific example of the motion quartet study, during the physical motion experiment, physical bottom-up and perceptual top-down signals are in agreement. We would therefore predict that these processes should activate most (or even the entirety) of a column. During ambiguous apparent motion, however, bottom-up and top-down signals are dissociated which means that we expect different parts of a column to be activated to different degrees. For example, if ambiguous motion was based on feedback that enters primarily in superficial layers, we would expect that part of a column to be more activated than other parts.

This example illustrates the potential benefit for understanding the cortical implementation of perceptual processes that could come from exploiting distinct termination patterns and studying the neuronal circuits implemented at different depth levels along a column. This will only be possible once we can reliably measure the distinct laminar contributions to particular columns. Although this has been achieved in a pioneering study \parencite{DeMartino2015}, current resolution limits hinder routine and reliable application, which will likely only become available once spatial resolution approaches 300 to 400 microns.

\subsection{Functional significance of columns}
Further validation of columnar fMRI studies and the ability to determine laminar contributions within a column will thus represent important steps for future UHF research. These developments will hopefully also shed light on the controversy surrounding the functional significance of columnar organization. Some authors have argued that cortical columns are structures devoid of function \parencite{Horton2005} based on the observation that no difference in visual performance is apparent between species that exhibit columnar organization in visual areas and those that do not. By contrast, other authors have successfully used columns as a fundamental functional unit to account for information processing in cortical computations \parencite{Bastos2012}.

We propose that currently a good working assumption for columnar fMRI studies is that the column offers a way to organize feedforward and feedback information around a common computational feature. For example, feedforward and feedback processing can be integrated for a particular orientation in V1 or a particular frequency in A1, which offers an efficient manner to process attentional or contextual effects \parencite{DeMartino2015}. We believe that, ultimately, empirical studies are the best way to advance the debate about the functional significance of columns. Studies should map out columnar structures in species that have them and test their relation to perception and cognition. In the motion quartet study, when mapping horizontal and vertical preferences in response to physical motion, response preferences were clustered in a columnar fashion. Furthermore, the representational content in these columnar structures appeared to be functionally relevant for conscious perception as each structure was involved in tracking a conscious percept of a particular motion axis.

\subsection{Richer representational content}
In this thesis, the representational content was either restricted to two sub-categorical features (horizontal or vertical motion; Chapter 3) or to one feature with several levels (different positions). An obvious extension for future work is to reveal the neural substrate for conscious content with multiple features and levels. The development of complex representational models such as deep neural networks \parencite{Kriegeskorte2014, Kriegeskorte2015, Yamins2016, Bashivan2019} together with methods that connect these models with brain activity \parencite{Kriegeskorte2008, Naselaris2011, Diedrichsen2017, Diedrichsen2018} now allow for mapping representational content with fMRI in cortical systems of humans along many stimulus features and feature dimensions. These developments lift most of the restrictions on the first step for studying content-specific NCC in humans and enable the mapping of rich representational content.  

Instead, we anticipate future challenges in the second step - finding appropriate methods for ambiguous stimulation in order to dissociate neural processes that pertain to conscious processing from those that pertain to sensory stimulation. For visual perception, several psychophysical methods are available to achieve this dissociation, including masking \parencite{Kouider2007, Breitmeyer2010}, bistable figures and binocular rivalry \parencite{Kim2005} as well as continuous flash suppression \parencite{Tsuchiya2005}. Some psychophysical methods might be more suitable for revealing content-specific NCC than others. For example, visual masking is not well suited for processes requiring sustained stimulation (such as motion processing, perceptual learning, temporal integration, etc) since stimuli become visible when presented for more prolonged periods \parencite{Faivre2014}. By contrast, continuous flash suppression can render stimuli invisible for long periods and offers reliable control of timing \parencite{Tsuchiya2005, Faivre2014}. As an alternative to psychophysical approaches, imagery or occlusion \parencite{Muckli2015} studies can be used to dissociate sensory and conscious processing because these studies lack the relevant sensory input (see below). Regardless of the specific method being used, it will be challenging to disentangle the exact contributions of single features and their distinct levels and many pairwise comparisons might be required to achieve this goal.

Another impediment to mapping richer representational content will be statistical power. Even mapping out just one feature with two states (Chapter 3), already required a single scanning sessions per participant (not including ambiguous stimulation). For the motion-dependent pRF study, we benefited from the large effect of visual field position on responses in early visual cortex. When moving to more complex content, limitations in statistical power can be anticipated since many different conditions will be required. Adding considerations about reproducibility, future consciousness research will benefit from small-N studies with many scanning sessions per participant.

\subsection{Reconstructing conscious experience}
For the study presented in Chapter 4, we grouped pRF and psychophysical estimates across all participants to increase statistical power. Although the group average was reflective of individual trends, there were also inter-individual differences that we did not account for; for example, some subjects showed larger perceptual displacements or larger pRF shifts than others. For future studies, it would be desirable to link the change in pRF estimates and perceptual shifts on a single-subject level. Such a model should be used to predict how much perceptual displacement a subject will experience based on the measured shift in pRF. Assuming that the hypothesized link between pRF estimates and position perception is correct, this should become feasible by collecting more data per participant and thus increasing statistical power.

More generally, the long-term goal for consciousness science should be to make accurate prediction from the brain activity of an individual to her or his conscious experience. The goal should not only be to decode different stimulus categories seen during training from brain activity (as has been done with MVPA). Instead, consciousness science should aim to make quantifiable predictions about the ongoing subjective experience. Such predictions should be made in a specific format by means of an appropriate reference space. For example, if visual consciousness is concerned, the reference space could be image space - with fluctuations in visual experience being reflected in time-varying images.

Such a goal might appear far-fetched or outright unreachable. Obvious obstacles in the way are that neural representations are noisy and high-dimensional \parencite{StYves2019}. Moreover, this goal re-emphasizes the need to distinguish neural processes pertaining to sensory information from those related to conscious experience. For example, it has been shown that the orientation of a stimulus can be decoded from response patterns in primary visual cortex even when there is no conscious awareness of the stimulus due to masking \parencite{Haynes2005}. Clearly, it is undesirable for information pertaining to unconscious processes to leak into the reconstruction of conscious experience. Problematically, it is conceivable that the involvement of cortical structures in conscious processing varies over time. Thus, the biggest obstacle will be the demarcation problem - clarifying which brain processes are conscious and which ones are not.

However, several considerations are also encouraging the pursuit of this goal. First of all, several successful attempts have shown that it is possible to reconstruct presented images from brain activity \parencite{Thirion2006, Miyawaki2008, Naselaris2009, Nishimoto2011, Schoenmakers2013, Senden2018, VanGerven2018, StYves2019}. In an important way, the task of reconstructing conscious experience from brain activity is more straightforward than that of reconstructing shown images: By most scientific and by many philosophical accounts of consciousness we should expect all information relevant for conscious experience to be available in the brain (but see \cite{ORegan2001}). By contrast, information about image details are incomplete given that not all aspects of an image are necessarily encoded by our senses \parencite{StYves2019}; these aspects of an image can never be recovered from brain activity. Furthermore, a few studies have shown that it is possible to reconstruct imagined images \parencite{Naselaris2015b} and letters \parencite{Senden2018} from brain activity. This is particularly encouraging for reconstruction of conscious experience since during imagery no sensory information from the stimulus was available (thus bypassing the demarcation problem).

Second, the necessary ingredients for reconstruction of conscious experience can already be specified. All of the above studies of (mental) image reconstruction shared one aspect: they all relied upon an encoding model that specified how stimuli in the external world are encoded in brain responses. Examples of used encoding models are the Gabor wavelet model \parencite{Kay2008}, the pRF model \parencite{Dumoulin2008} or the feature-weighted RF model \parencite{StYves2017}. All these models specify a mapping from image space to patterns of brain activity. The feature-weighted RF model is neutral with regard to the features that are encoded and can be employed with any model that specifies such a mapping, including deep CNNs. All of the above studies collected independent data that could be used to fit the parameters of the encoding model to every individual participant. For reconstruction, the mapping then needs to be inverted such that it points from brain response patterns to image space, for which different solutions exist \parencite{Naselaris2009, Rezende2014, Senden2018, StYves2019}.

Reconstruction of conscious experience can proceed in a similar manner with the additional requirement that appropriate methods (such as continuous flash suppression) are employed that allow for dissociating brain responses for conscious and unconscious processing. The idea is to obtain brain responses that result from the contrast between conscious and unconscious processing of the same stimulus. An interesting question is whether these brain responses should be used for fitting parameters of the encoding model (step A) or during reconstruction (step B) (or both). For letter and image imagery, parameters were fitted using data from conventional presentation of letters or natural images \parencite{Naselaris2015b, Senden2018} and only reconstruction was based on imagery data. This approach relies on the assumption that neural processes are shared between perception and imagery, which is supported by evidence \parencite{Pearson2015}. However, we know that unconscious and conscious processes do not share the same neuronal processes. Alternatively, brain responses resulting from the contrast between conscious and unconscious processing can be used in both step A and step B, as long as the two steps rely on data sets that are independent from one another. Finally, a third possibility is to use these brain responses only to fit the parameters of the encoding model and then to use an inversion of the established mapping to reconstruct the stream of consciousness experience without employing any dissociative techniques in step B. Future research should explore these two possibilities.

\section{Conclusion: Chalmer's fallen caveat}
Neuroimaging in humans was previously thought to be ill-suited to investigate content-specific NCC given difficulties to reliably map and track representational content for neural systems in humans. We have named this provision for human neuroimaging methods "Chalmer's caveat" after the author that originally formulated it \parencite{Chalmers2000}. This thesis can be understood as a demonstration that, with the introduction of UHF scanners and the development of appropriate fMRI analysis techniques, Chalmer's caveat no longer holds for fMRI studies. It is now possible to map sub-categorical representational content in human cortical systems and to formulate and test mechanisms that link these representations to conscious experience. The future will see even richer representational content and potentially even the ability to reconstruct conscious experience from our brain responses.

\clearpage
\printbibliography[heading=subbibnumbered, title={References}]

