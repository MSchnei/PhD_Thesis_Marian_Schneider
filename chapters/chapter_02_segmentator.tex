\chapter[A scalable method to improve gray matter\\ segmentation at ultra-high field mri]{A scalable method to improve\\ gray matter segmentation\\ at ultra-high field MRI}
\chaptermark{Improving gray matter segmentations using 2D histograms}
\label{ch:chapter02}
\paperciteone

\clearpage{\thispagestyle{empty}\cleardoublepage}

\section{Abstract}
High-resolution (functional) magnetic resonance imaging (MRI) at ultra-high magnetic fields (7~Tesla and above) enables researchers to study how anatomical and functional properties change within the cortical ribbon, along surfaces and across cortical depths. These studies require an accurate delineation of the gray matter ribbon, which often suffers from inclusion of blood vessels, dura mater and other non-brain tissue. Residual segmentation errors are commonly corrected by browsing the data slice-by-slice and manually changing labels. This task becomes increasingly laborious and prone to error at higher resolutions since both work and error scale with the number of voxels. Here we show that many mislabeled, non-brain voxels can be corrected more efficiently and semi-automatically by representing three-dimensional anatomical images using two-dimensional histograms. We propose a representation based on intensity values and their first spatial derivative and quantify the benefits in 7~Tesla MRI data of nine volunteers. We present an openly accessible Python implementation of this approach and demonstrate that editing cortical segmentations using two-dimensional histogram representations as an additional post-processing step aids existing algorithms and yields improved gray matter borders. By making our data and corresponding expert (ground truth) segmentations openly available, we facilitate future efforts to develop and test segmentation algorithms on this challenging type of data.

\section{Introduction}
Magnetic resonance imaging (MRI) has become one of the most important tools to study human brain function and structure in vivo. Moving from high (3 Tesla [T]) to ultra-high (7 and 9.4 T) magnetic fields (UHF), together with improvements in acquisition methods, leads to increases in signal and contrast-to-noise (SNR and CNR, respectively) \parencite{Vaughan2001, Duyn2011, Ugurbil2014}. The increase in SNR can be leveraged to increase voxel resolution of both functional and structural images to sub-millimeter scales. Such sub-millimeter spatial resolutions allow for in vivo studies that probe cortical properties at the mesoscale \parencite{DeMartino2016, Kemper2017, Dumoulin2017, Polimeni2017, Trampel2017}. These studies include (i) cortical-depth dependent analyses of function \parencite{Polimeni2010, Koopmans2011, DeMartino2013, Huber2015, Muckli2015, Kok2016} and structure \parencite{Kemper2017,Waehnert2014,Trampel2017}, (ii) the mapping of cortical columnar structures \parencite{Yacoub2008, Zimmermann2011, DeMartino2015, Goncalves2015, Nasr2016, Tootell2017} as well as (iii) sub-millimeter cortical topography \parencite{Harvey2013, Harvey2015, DeMartino2015, Fracasso2016}.

Such studies crucially depend on accurate and precise delineations of the gray matter (GM) ribbon both at the inner (white matter; WM) and outer (cerebrospinal; CSF) border. Since the aim of these studies is to investigate how the (functional) MRI (f/MRI) signal varies as a function of small position changes in GM, systematic GM segmentation errors would invalidate the conclusions drawn from these studies. Consider, as an example, an fMRI study conducted with a voxel resolution of 0.8 mm isotropic. Assume an average thickness of human cortex of 2.4 mm and a true signal change at the upper cortical depth level. In this study, under optimal conditions the functional resolution would allow a straight piece of cortical ribbon to be divided in three relative cortical depths, each of them one voxel thick. Falsely labeling an additional fourth voxel as GM would make the difference between reporting an fMRI signal change at most superficial (false voxel excluded) or mid-superficial (false voxel included) cortical depth level. This example stresses the importance of accurate and precise GM segmentations. 

Obtaining accurate and precise definitions of the GM ribbon, however, is currently a difficult and time-consuming task for sub-millimeter UHF data. The increases in SNR, CNR and resolution attainable with UHF as well as analysis \parencite{Moortele2009} and reconstruction \parencite{Marques2010} strategies specific to UHF reveal several structures outside of the brain that were barely visible on images obtained at conventional field strengths (1.5 and 3 T) and lower resolution ($> 1$ mm isotropic) \parencite{Viviani2017}. Such structures include the dura mater \parencite{VanderKouwe2008}, medium-sized blood vessels in the sulci \parencite{Viviani2016} as well as draining sinuses and connective tissue adjacent to GM \parencite{Helms2006}. To date, many of the existing brain segmentation algorithms have been developed and benchmarked on images collected at 1 mm isotropic resolution or lower and at conventional field strengths \parencite{Helms2016} (but see \cite{Bazin2014}). If segmentation algorithms do not model these non-brain structures they might falsely label (part of) these structures as GM. Faced with such segmentation errors, researchers commonly correct the misclassified voxels manually. However, the increase in resolution leads to an exponential increase in the number of voxels, which renders manual correction a laborious task. Furthermore, manual correction is prone to error and may introduce an observer bias, thereby reducing the reproducibility of subsequent analyses \parencite{Despotovic2015}. This currently leaves researchers with the dilemma of accepting the likely erroneous outcome of automatic segmentation algorithms or performing a time-consuming and error-prone manual correction.

CBS tools \parencite{Bazin2014} directly tackle many of the challenges of UHF high-resolution anatomical data by, for example, including pre-processing steps to estimate dura mater and CSF partial voluming. Consequently, these tools provide an improved initial GM segmentation compared to other solutions \parencite{Bazin2014}. However, we show that in many cases the initial CBS segmentation can be further improved with the approach proposed here. Furthermore, CBS tools have been optimized for whole-brain data obtained with the MP2RAGE sequence \parencite{Marques2010}. While the MP2RAGE sequence is commonly used at UHF as a basis for brain tissue class segmentations, we note that many high-resolution studies at UHF also use alternative sequences to define GM \parencite{Huber2015, Renvall2016, Kashyap2017,Moortele2009}, some of which offering partial coverage of the brain only \parencite{Huber2015, Kashyap2017}. In such cases, alternative approaches that do not depend on particular templates, atlases or other forms of prior information are useful and required.

Here, we show that non-brain voxels misclassified as GM can largely be corrected using a multi-dimensional transfer function that is specified based on a two-dimensional (2D) histogram representation \parencite{Kindlmann1998, Kniss2001, Kniss2005, Ip2012} of three-dimensional (3D) MRI brain data. We demonstrate that this transfer function offers an efficient way to single out non-brain tissue voxels. Removing these voxels from GM classifications found by automatic segmentation pipelines improves GM segmentations. This approach addresses the problems of an entirely manual correction, since it yields a meaningful summary representation of the data that allows to manipulate the data efficiently. As a consequence, it is both more time efficient than manual slice-by-slice correction and it reduces observer bias.

This chapter is intended as a demonstration that 2D histogram based methods are useful for improving segmentations of MRI images. In particular, we aim to show that, for images acquired at sub-millimetre resolution and very high field strength, 2D histogram based methods offer an efficient way to obtain a more refined brain mask that excludes usually undesired structures like vessels and dura mater. Several alternatives to the methods presented here exist for data visualization, dimensionality reduction, or data fusion, for example, principal component analysis \parencite{PCA2002}, multidimensional scaling \parencite{MDS2005} or the t-SNE algorithm \parencite{VanDerMaaten2008}. A detailed quantification of the merits and disadvantages of these methods, however, is beyond the scope of this chapter which is intended to introduce a simple and fast solution. Likewise, there are alternative ways of defining clusters in an image to the normalized graph cut algorithm that we have used here \parencite{Venkataraju2009, Jain2011, Liu2012, NunezIglesias2013}. While all these methods have their merit, we decided to use normalized-cut multilevel segmentation since it already has been shown to work successfully on the 2D histogram representations of volumetric data \parencite{Ip2012}.

We structured the chapter as follows. In Section \ref{sec:Theory}, we introduce the technique of specifying transfer functions based on 2D histogram representations of voxel intensity and gradient magnitude. We offer theoretical considerations for why this technique is suited to remove vessels and dura mater voxels in high-resolution MRI data ($< 1$ mm isotropic voxel size). In Section \ref{sec:DataRequirements} we outline required features of the input data and recommended data pre-processing steps. In Section \ref{sec:ValidationMethods} and \ref{sec:ValidationResults} we validate the suggested method by evaluating obtained GM segmentation results against expert GM segmentations obtained for nine subjects recorded at 7~T. We demonstrate considerable improvement in segmentation performance metrics. We have implemented the method described here in a free and open Python software package \parencite{segmentator_v1.5.0}. The package as well as validation data, corresponding expert segmentations, and processing scripts used to validate the proposed method are all openly available (see Table~\ref{tab:availability}).

\section{Transfer functions and histograms}
\label{sec:Theory}

\subsection{Multi-dimensional transfer functions}
In the context of MRI data visualization, a transfer function can be understood as a mapping of voxel data to optical properties such as color and opacity. Effective transfer functions make structures of interest in the data visible. This can, for example, be achieved by assigning low opacity values to voxels that make up irrelevant structures and by highlighting desired structures with high opacity and salient color values. Multi-dimensional transfer functions assign renderable properties based on a combination of values \parencite{Kniss2002, Kindlmann1998, Kniss2005, Kniss2001}. This is important in the context of MRI data where features of interest are often difficult to extract based on a single value alone. Considering multiple values increases the chances of uniquely isolating a feature and making it visible \parencite{Kniss2002}.

In theory, multi-dimensional transfer functions could be used to perform exhaustive tissue-type segmentation of human brain MRI data. In this process, each voxel would be classified as either WM, GM, or CSF by specifying appropriate transfer functions. It has been shown, however, that this approach is less successful than other, bespoke brain segmentation algorithms \parencite{Ljung2016}. Here, we propose that transfer function-based methods still have a role to play in UHF MRI brain segmentation pipelines because they are well-suited for efficient removal of mislabeled non-brain tissue. We motivate this proposition by considering that brain and non-brain voxels become separable in 2D histogram representations.

\subsection{2D histogram representation}
2D histogram representations have been shown to greatly facilitate the process of specifying effective, 2D transfer functions \parencite{Kindlmann1998, Kniss2005}. 2D histograms are obtained by taking an n-dimensional data set and binning its data points along two dimensions. In principle, a 2D histogram can be obtained from any two sets of values. A 2D histogram, plotting gradient magnitude against image intensity, however, has been shown to be particularly useful for identifying tissue boundaries \parencite{Kindlmann1998, Kniss2005}. The term gradient magnitude here refers to the magnitude of the vector that represents the spatial intensity gradient at every MRI voxel, where the spatial intensity gradient is equal to the first spatial derivative of the image intensity values.

Figure~\ref{fig:Fig1} shows how 3D MRI data of a human brain are represented in a 2D histogram (a T1w image was divided by a PDw image [\cite{Moortele2009}] and brain extracted; images were acquired with 0.7 mm isotropic resolution; for more details see Section \ref{sec:ValidationMethods}). The histogram is obtained by plotting gradient magnitude against image intensity. In this representation, different tissue types occupy different regions. CSF voxels are characterized by very low intensity and low gradient magnitude values and therefore occupy the lower-left space of the histogram. GM and WM voxels have medium to high intensities and very low gradient magnitudes. Therefore, these tissue classes form circular regions at the bottom-center of the histogram. Voxels at the GM-WM interface fall within an arc reaching from medium to high intensities, following a low to medium to low gradient magnitude trajectory. Similarly, voxels at the CSF-GM interface span an arc from low to medium intensities. Finally, blood vessels and dura mater are thin structures characterized by very high gradient magnitudes and medium to high intensities. Therefore, these structures occupy up-center and up-right parts of the 2D histogram.

\begin{figure}[htb!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02/figure_1.png}
\caption{2D histogram representation for MRI image of a human brain. \textbf{(A)} Intensity and \textbf{(B)} gradient magnitude values of a brain extracted T1w-divided-by-PDw MRI image are represented in a \textbf{(C)} 2D histogram. Darker regions in the histogram indicate that many voxels in the MRI image are characterized by this particular combination of image intensity and gradient magnitude. \textbf{(D)} The 2D histogram displays a characteristic pattern with tissue types occupying particular areas of the histogram. Voxels containing CSF, dura mater or blood vessels (black dashed lines and arrows) cover different regions of the histogram than voxels containing WM and GM (red dashed lines). As a result, brain tissue becomes separable from non-brain tissue.}
\label{fig:Fig1}
\end{figure}

Since different tissue types occupy different regions in the 2D histogram, each tissue type and boundary can, in principle, be isolated using a 2D transfer function based on image intensity and gradient magnitude. For the purposes of this chapter, we focus on the distinction between brain (WM, GM, GM-WM interface) and non-brain (CSF, CSF-GM interface, blood vessels, dura mater) voxels. The intensity-gradient magnitude histogram is particularly suited to distinguish non-brain tissue because voxels containing dura mater and vessels are characterized by high gradient magnitude values. Given the typical voxel sizes of current high resolution studies, gradient magnitude will be high in the entirety of these structures (see Figure~\ref{fig:Fig1}B for an example) and the combination of high intensity and high gradient magnitude values renders those structures separable from WM and GM voxels.

\subsection{Creating transfer functions}
The simplest way to create a transfer function is to explore the data by moving widgets with a specified shape over the 2D histogram representation \parencite{Kniss2005}. For example, Figure~\ref{fig:Fig2} shows how a circular sector could be moved on top of the 2D histogram to highlight particular regions. In this case, only MRI voxels whose intensity-gradient magnitude combination falls within the highlighted region of the 2D histogram would be selected. Position and size of the circular sector can then be refined until the desired data have been isolated.

\begin{figure}[htb!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02/figure_2.png}
\caption{Creation of 2D transfer functions with pre-defined shapes. \textbf{(A)} Intensity and \textbf{(B)} gradient magnitude values of a brain extracted T1w-divided-by-PDw MRI image are represented in a 2D histogram. By moving widgets of pre-defined shape, e.g. a circle, over the \textbf{(C)} 2D histogram and \textbf{(D)} concurrent visualization of selected voxels on a 2D slice of brain, positions of different tissue types in the 2D histogram can be probed and transfer functions can be created. In this example, the different probe positions (yellow, orange and red circles) appear to contain different aspects of GM.}
\label{fig:Fig2}
\end{figure}

Using such a straightforward process of exploration and refinement \parencite{Kniss2002}, however, might yield slightly sub-optimal results. The shape of the widget might not capture the ideal shape given the data or the user might lack the prior knowledge that is required for this task. Alternatively, hierarchical exploration of normalized graph cut decision trees can be used \parencite{Ip2012}. This graph cut method results in a set of components (i.e. clusters) of the histogram that are mutually exclusive and collectively exhaustive. This allows the user to split and merge clusters in a data-driven and intuitive way that can be aided by the immediate visualization of the resulting segmentation (Figure~\ref{fig:Fig3}). The method allows for semi-automatic tissue selection, i.e. the shape of the clusters is data-driven but the decision which clusters to join and which to divide is made by the user.

\begin{figure}[htb!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02/figure_3.png}
\caption{Creation of 2D transfer functions with data-driven shapes. \textbf{(A)} The user starts with the 2D histogram representation of image intensity and gradient magnitude (left side) and concurrent visualization of the original brain data (right side). The user can then interact with and select data in the 2D histogram to specify transfer functions. In this example, this was done with the help of a normalized graph cut decision tree. \textbf{(B)} The interaction with the 2D histogram results in data-driven shapes of selected areas, here shaded in pink, green and blue (left side). Voxels selected by those areas are highlighted in corresponding colors against the backdrop of the original brain data (right side). The visualization reveals that the area of the 2D histogram shaded in blue selects brain voxels, while the areas shaded in green and pink select CSF* and blood vessel voxels**/dura mater***, respectively.}
\label{fig:Fig3}
\end{figure}

\section{Input data requirements and preparation}
\label{sec:DataRequirements}
\subsection{Data preparation}
In order to obtain optimal results with the gradient-magnitude method, several pre-processing steps should be performed on the data. Ranging from absolutely necessary to desired (but not critical), these pre-processing steps include: (i) bias field correction, (ii) brain extraction, (iii) cerebellum removal and (iv) removal of brain stem structures. Successful bias field correction is critical to performance since otherwise intensity values for different tissue types start to mix in 2D histogram space. Brain extraction should be performed to remove irrelevant voxels from the 2D histogram representation. Removal of cerebellar and brain stem structures is recommended since it further improves conformity to ideal 2D histogram shapes (Figure~\ref{fig:Fig1}D). Bias field correction and brain extraction can be performed using automatic algorithms \parencite{Smith2002, Ashburner2005}. Removal of cerebellum and sub-cortical structures might require the manual creation of masks. We note, however, that generation of these masks is only desired, not strictly necessary. Furthermore, generation of these masks is often a desirable processing step for many automatic tissue class segmentation algorithms, since it improves their performance as well.

\subsection{Data requirements}
Suitability of the intensity-gradient magnitude histogram for separating brain from non-brain tissue will depend on the resolution and CNR of the input data. We expect a lower limit of resolution around 1 mm. At resolutions lower than that, the intensity-gradient magnitude method will yield unsatisfactory results due to partial voluming between the thin structures we are aiming to correct and surrounding CSF or tissues. We do not expect an upper resolution limit for the input data. Although, initially, values in the gradient magnitude image will no longer be high in all vessel and dura mater voxels, very high-resolution images can still be accommodated by choosing the appropriate level of smoothness on the gradient magnitude image. In Figure~\ref{fig:S1_Fig}, we demonstrate that by setting the appropriate smoothness level of a Deriche filter \parencite{Deriche1987}, gradient magnitude images for very high resolution data (0.25 mm isotropic; \cite{250micron_data, Lusebrink2017}) can be approximated to those observed for data at lower resolution (0.7 mm isotropic).

We furthermore expect our method to be impacted by the CNR of the input data. Figure~\ref{fig:S2_Fig} shows that with added Gaussian noise (i.e., decreasing CNR) the desired circular and arc-like shapes in the 2D histogram (Figure~\ref{fig:Fig1}D) become less apparent. At very high noise levels separating brain from non-brain tissue in the 2D histogram space becomes challenging (see e.g. Figure~\ref{fig:S2_Fig}). While the in-depth evaluation of additional processing tools is beyond the scope of the present chapter, we note that if the input data are very noisy, smoothing can be applied. In particular, non-linear anisotropic diffusion based smoothing \parencite{Weickert1998, Mirebeau2015} results in the data regaining the desired 2D histogram shapes (see Figure~\ref{fig:S3_Fig}).

The parameter space of the input data is thus constrained by resolution and CNR. Apart from these restrictions, our methods are suitable for any 3D image and work irrespective of the field-of-view of the acquisition (partial coverage is possible) and membership to a particular species (bottle-nose dolphin brain is also possible; for examples see Figure~\ref{fig:S4_Fig}).

\section{Validation methods}
\label{sec:ValidationMethods}
\subsection{Overview}
In order to validate the method proposed above, we created two validation data sets based on the acquisition of high-resolution 7~T data of nine subjects and corresponding manually-guided expert segmentations of GM. In particular, we created two validation sets based on two of the most common acquisition sequences. For five subjects, we collected MPRAGE T1w and PDw data (we refer to this data set as the MPRAGE data set below). For four different subjects, we collected MP2RAGE data, to obtain unbiased (uni) images (we refer to this data set as the MP2RAGE data set below). Both data sets can be downloaded from \cite{shared_dataset}.

\subsection{Ethics statement}
The experimental procedures were approved by the ethics committee of the Faculty for Psychology and Neuroscience (MPRAGE data set) and the Medical Ethical Committee at the Faculty of Health, Medicine and Life Sciences (MP2RAGE data set) at Maastricht University, and were performed in accordance with the approved guidelines and the Declaration of Helsinki. Written informed consent was obtained for every participant before conducting the experiments.

\subsection{MRI acquisition parameters}
All images were acquired on a Siemens 7~T whole body scanner (Siemens Medical Solutions, Erlangen, Germany) using a head RF coil (Nova Medical, Wilmington, MA, USA; single transmit, 32 receive channels). In all acquisitions, we used dielectric pads \parencite{Teeuwisse2012}.

For $n$=5 subjects (age range 24-30, 2 females, no medical condition), the MPRAGE data set consisted of: a T1w image using a 3D MPRAGE sequence (repetition time [TR] = 3100 ms; time to inversion [TI] = 1500 ms [adiabatic non-selective inversion pulse]; time echo [TE] = 2.42 ms; flip angle = 5°; generalized auto-calibrating partially parallel acquisitions [GRAPPA] = 3 \parencite{Griswold2002}; field of view [FOV] = 224 × 224 mm\textsuperscript{2}; matrix size = 320 × 320; 256 slices; 0.7 mm isotropic voxels; pixel bandwidth = 182 Hz/pixel; first phase encode direction anterior to posterior; second phase encode direction left to right), a PDw image (0.7 mm isotropic) with the same MPRAGE as for the T1w image but without the inversion pulse (TR = 1380 ms; TE = 2.42 ms; flip angle = 5°; GRAPPA = 3; FOV = 224 × 224 mm\textsuperscript{2}; matrix size = 320 × 320; 256 slices; 0.7 mm iso. voxels; pixel bandwidth = 182 Hz/pixel; first phase encode direction anterior to posterior; second phase encode direction left to right).

For $n$=4 subjects (age range 24-58, 2 females, no medical condition) the MP2RAGE data set consisted of: 3D MP2RAGE data (TR = 5000 ms; TI1/TI2 = 900/2750 ms; TE = 2.46 ms; FA1/FA2 = 5°/3°; FOV = 224 × 224 mm\textsuperscript{2}; matrix size = 320 × 320; slices = 240; 0.7 mm iso. voxels) \parencite{Marques2010}. More details on the MP2RAGE data acquisition can be found in \cite{Haast2016}.

\subsection{Manually-guided expert segmentations}
For every subject, we established 'ground truth' GM classifications via manually-guided expert segmentations. All segmentations were created manually by the same expert (OFG), using ITK-SNAP \parencite{py06nimg} and a graphics tablet (Intuos Art; Wacom Co. Ltd; Kazo, Saitama, Japan). Segmentations were only established for cortical GM, since cerebellar and sub-cortical structures were later removed in a pre-processing step. To establish the segmentation, the expert used T1w images for the MPRAGE and uni images for the MP2RAGE data set. To avoid resulting tissue type classification to be ragged, the expert followed a particular processing sequence. The brain was first traversed in a single direction (e.g. sagittally) and the ground truth was established slice-by-slice. Subsequently, the brain was traversed in the two other directions (e.g. axially, then coronally). This sequence was repeated several times across several regions until the GM segmentation of the whole brain was considered of good quality. To further ensure the quality of the resulting segmentation, they were inspected for mistakes by two additional experts (MS and FDM).

\subsection{Software implementation}
We implemented the creation of transfer function based on 2D histograms in an open source Python package called Segmentator \parencite*{segmentator_v1.5.0}, which is built upon several other scientific packages such as Numpy \parencite*{numpy2011}, Scipy \parencite*{scipy2001}, Matplotlib \parencite*{matplotlib2007} and Nibabel \parencite*{nibabel2017}. Segmentator allows for selection of data points in a 2D histogram (for example gradient magnitude over intensity) and concurrent visualization of selected brain voxels on a 2D slice. Data points can be selected using a circular sector widget with variable reflex angle and radius. Alternatively, data selection can be performed using the normalized graph cut (n-cut) method (i.e. spectral clustering) as described above. The n-cut algorithm from Scikit-image \parencite*{scikitimage2014} was modified to export an augmented output which provides step-wise access to independent branches of the decision tree and employed in Segmentator (the modification is available as a  \href{https://github.com/ofgulban/scikit-image/tree/ncut-rag-options}{GitHub repository}).

The package provides several options to calculate the gradient magnitude image. All the 2D histogram analyses described in this chapter were based on gradient magnitude images that were computed as the Euclidean norm of the first spatial derivative estimated using a $3 \times 3 \times 3$ Scharr kernel \parencite{Scharr2000, Jahne2000}. Subsequently, transfer functions were specified using the normalized graph cut algorithm and user intervention for the selection of the non-brain tissue transfer functions. Processing data for a single subject took about 10 minutes on average. The Segmentator package is openly and freely accessible as a \href{https://github.com/ofgulban/segmentator}{GitHub repository}.

\subsection{Segmentation procedure}
For both validation data sets, we followed similar procedures, with modifications where necessary to accommodate for differences in the sequences' output. Our goal was to obtain initial GM segmentations from existing, fully-automated segmentation algorithms and to quantify the improvement in segmentation accuracy that can be obtained when using the method described here as post-processing steps. To establish the initial GM segmentations we used FSL FAST \parencite{Zhang2001} and the SPM 12 "unified segmentation" algorithm \parencite{Ashburner2005} for the MPRAGE data set and FSL FAST and CBS tools \parencite{Bazin2014} for the MP2RAGE data set. SPM and CBS tools have been developed and benchmarked on MPRAGE and MP2RAGE images respectively. FSL FAST is suited to process either type, so we used it for both data sets. We then quantified the impact of using transfer functions based on 2D histogram representations of intensity and gradient magnitude (see Section \ref{sec:Theory}) as an additional post-processing steps. This procedure will be referred to below as the gradient magnitude (GraMag) method. The GraMag method resulted in a mask that could be used to further refine the initial GM segmentation, e.g. by removing blood vessels and dura mater that were falsely labeled as GM initially. The analysis procedures for the two validation data sets are summarized in flow chart diagrams (Figure~\ref{fig:S5_Fig} and \ref{fig:S06_Fig}). Furthermore, in an effort to make our analyses fully reproducible, we made the Python and bash scripts used for pipeline processing openly available at \cite{segmentator_processing_scripts}.

For the MPRAGE data set, we first computed ratio images (T1w divided by PDw) \parencite{Moortele2009} to reduce inhomogeneities. Ratio images were input to either FSL FAST or SPM 12. FSL FAST was used with default values. The FAST algorithm requires an initial brain extraction procedure that we performed using FSL BET \parencite{Smith2002}. Additionally, we masked the images to exclude: the corpus callosum, the basal ganglia, the hippocampus, the entire brain stem and the cerebellum. Below we refer to this mask as 'NoSub mask'. The NoSub mask was created manually for every subject. In SPM 12 we used default settings with one exception. We set the number of Gaussians to be modeled to 3 for GM and 2 for WM (default values are 1 and 1), which in our experience yields improved results for 7~T data. As part of their standard segmentation routine, both FSL FAST and SPM 12 perform initial inhomogeneity correction. We inspected the bias-corrected images to ensure that the algorithms had converged on plausible solutions. We specified for the FSL FAST algorithm to output hard segmentation labels. Since SPM 12 outputs probabilities for six tissue classes, we transformed this soft output to hard segmentation labels by assigning each voxel to the tissue class with the highest posterior probability. Since the SPM segmentation algorithm works best with unmasked images, we applied the NoSub mask only to the resulting SPM GM segmentations, not to the input data. The resulting GM segmentations from FSL and SPM were saved for later evaluation.

We proceeded with bias-corrected ratio images from either SPM or FSL (Figure~\ref{fig:S5_Fig}). Since the GraMag method works best with brain extracted images, we combined SPM's WM and GM segmentation outcomes to form a brain mask and performed brain extraction of the ratio images from SPM. After brain extraction, we also excluded cerebellum and brain stem tissue using the NoSub mask. FSL's bias-corrected ratio images did not require masking as the brain extraction (and cerebellum removal) was already performed before segmentation. We used the 2D histogram representation of intensity and gradient magnitude together with the hierarchical exploration of normalized graph cut decision trees (as described in Section \ref{sec:Theory}) to create transfer functions. Exploration of decision trees was limited to an 8-level hierarchy. The criterion for splitting and merging clusters was subjective: a rater (MS) aimed to obtain shapes that resembled the ideal template shapes (Figure~\ref{fig:Fig1}D) as closely as possible, given the 2D histogram representation and concurrent visualization of selected voxels. However, selection of voxels was well constrained by clearly-outlined shapes in the 2D histogram representation and commonly required to move down the decision tree hierarchy by only 2 or 3 levels. Exploration of the decision tree took about 30 to 60 seconds per subject. Generation of normalized graph cut decision trees, which was done previous to exploration by a rater, took about 5 minutes on a workstation  (RAM: 32 GB, 12 cores (6 virtual); CPU: 2.146 GHz; operating system: Debian 8). The transfer function resulting from this procedure was used to separate brain from non-brain tissue voxels. Non-brain tissue voxels were removed from GM if they were included in the initial FSL and SPM segmentations.

For the MP2RAGE data set, the T1 map, T1w (uni) and second inversion image from the MP2RAGE sequence were input to CBS tools \parencite{Bazin2014}. Only the brain-extracted \parencite{Smith2002} uni image was input to FSL FAST, since this resulted in higher performance than inputting all three images. Both FSL FAST and CBS tools were run with default settings. Note that the default settings for CBS tools include removal of non brain tissue by estimating dura mater and CSF partial voluming. The resulting GM segmentations from FSL and CBS were saved for later evaluation. We proceeded with the FSL FAST bias-corrected, brain-extracted and NoSub masked uni image as for the MPRAGE data set to obtain a secondary brain mask (Figure~\ref{fig:S06_Fig}).

\subsection{Quantification}
The segmentation procedures resulted in two different GM segmentations for each data set and initial segmentation algorithm (SPM or CBS and FSL FAST): (i) an initial segmentation without any further changes, (ii) after correction using the GraMag method. To compare segmentation quality among these two outcomes, we calculated the Dice coefficient (DICE) and the Average Hausdorff Distance (AVHD) using the openly available EvaluateSegmentation Tool (2016; VISCERAL; \href{http://www.visceral.eu}{www.visceral.eu}).

The DICE is an overlap-based metric and it is the most popular choice for validating volume segmentations \parencite{Taha2015}. We included it here as a familiar reference for the reader. However, overlap-based metrics like the DICE are not recommended for validating segmentation boundaries against the ground truth, as is our aim here, since they are relatively insensitive to boundary errors. In contrast, the AVHD is a distance metric sensitive to boundary errors \parencite{Taha2015}. We therefore consider the AVHD to be a more suitable metric for our purposes and we based our conclusions on the comparisons made with the AVHD. 

Given that the AVHD quantifies the similarity of two boundaries, we first extracted WM-GM and GM-CSF boundaries from the ground truth segmentations and the different GM segmentations before calculating the AVHD. Here, an AVHD of zero indicates a perfect match between the segmentation and ground truth boundaries, while values larger than zero indicate a mismatch. In this case, the value represents the average number of voxels by which the two boundaries deviate from one another.

\section{Validation results}
\label{sec:ValidationResults}
Visual inspection revealed that applying the GraMag method excluded most of the vessels and dura mater voxels and resulted in a more plausible GM matter definition for both MPRAGE and MP2RAGE data sets (see Figure~\ref{fig:Fig4}).

\begin{figure}[htb!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02/figure_4.png}
\caption{Comparison of GM segmentation results. GM segmentation results are shown on the transverse slices of two representative subjects for the MPRAGE (upper row) and the MP2RAGE (lower row) data set before and after applying the GraMag method. The original image that is input to the segmentation is shown on the left. The initial GM segmentation obtained with SPM 12 or CBS tools is shown in red. GM segmentations after additional polishing with brain mask obtained with the GraMag method are overlaid in blue. Additional masking removes CSF*, blood vessels**, and most of dura mater*** voxels from the initial GM definitions.}
\label{fig:Fig4}
\end{figure}

Table~\ref{tab:table1} compares segmentation performance before and after applying the GraMag method to the initial GM segmentations for the MPRAGE data set. The GraMag method led to an improvement of GM segmentations in all subjects for segmentations from SPM 12 and all but one subject for segmentations from FSL FAST. On average, the AVHD decreased from 0.735 $\pm$ 0.100 (mean $\pm$ standard deviation across subjects) to 0.580 $\pm$ 0.022 for SPM 12 and from 0.601 $\pm$ 0.083 to 0.572 $\pm$ 0.073 for FSL FAST. The GraMag method did not affect the DICE coefficient. On average, it changed very little from 0.866 $\pm$ 0.014 to 0.860 $\pm$ 0.021 for SPM 12 and from 0.870 $\pm$ 0.015 to 0.873 $\pm$ 0.019 for FSL FAST.

\begin{table}[!ht]
\centering
\caption{
Segmentation performance scores MPRAGE data set. The table shows the DICE (larger is better) and AVHD (less is better) for the initial SPM 12 and FSL FAST GM segmentations before and after applying the gradient magnitude method. DICE, DICE Coefficient; AVHD, Average Hausdorff Distance; Init, initial segmentation; GraMag, gradient magnitude method.}
\begin{tabular}{llllll}
\\
\toprule
     &                & SPM   & SPM   & FAST  & FAST  \\
     &                & DICE  & AVHD  & DICE  & AVHD  \\
\midrule
 S02 &                &            &            &             &             \\
     & Init           & 0.8576     & 0.7413     & 0.8896      & 0.5375      \\
     & Init + GraMag  & 0.8594     & 0.5865     & 0.8902      & 0.4980      \\
 S03 &                &            &            &             &             \\
     & Init           & 0.8644     & 0.8753     & 0.8694      & 0.5739      \\
     & Init + GraMag  & 0.8376     & 0.6139     & 0.8781      & 0.5612      \\
 S05 &                &            &            &             &             \\
     & Init           & 0.8569     & 0.6379     & 0.8782      & 0.5230      \\
     & Init + GraMag  & 0.8688     & 0.5647     & 0.8909      & 0.5233      \\
 S06 &                &            &            &             &             \\
     & Init           & 0.8601     & 0.7789     & 0.8635      & 0.6477      \\
     & Init + GraMag  & 0.8435     & 0.5797     & 0.8616      & 0.5909      \\
 S07 &                &            &            &             &             \\
     & Init           & 0.8897     & 0.6403     & 0.8490      & 0.7228      \\
     & Init + GraMag  & 0.8893     & 0.5574     & 0.8460      & 0.6862      \\
\bottomrule
\end{tabular}
\label{tab:table1}
\end{table}

Table~\ref{tab:table2} compares segmentation performances before and after applying the GraMag method to the segmentations for the MP2RAGE data set. The GraMag method decreased AVHD for all but one subject and, on average, from 0.544 $\pm$ 0.121 to 0.477 $\pm$ 0.087 for CBS tools and from 1.012 $\pm$ 0.043 to 0.830 $\pm$ 0.082 for FSL FAST. On average, it slightly increased the DICE coefficient for initial CBS tools segmentations from 0.861 $\pm$ 0.024 to 0.868 $\pm$ 0.028 and decreased the DICE coefficient for FSL FAST segmentations from 0.804 $\pm$ 0.035 to 0.785 $\pm$ 0.034.

\begin{table}[!ht]
\centering
\caption{
Segmentation performance scores MP2RAGE data set. The table shows the DICE (larger is better) and AVHD (less is better) for the initial CBS tools and FSL FAST GM segmentations before and after additional masking using the gradient magnitude method. DICE, DICE Coefficient; AVHD, Average Hausdorff Distance; Init, initial segmentation; GraMag, gradient magnitude method.}
\begin{tabular}{llllll}
\\
\toprule
     &                 & CBS   & CBS   & FAST  & FAST  \\
     &                 & DICE  & AVHD  & DICE  & AVHD  \\
\midrule
 S001 &                &            &            &             &             \\
      & Init           & 0.8688     & 0.4081     & 0.8157      & 1.0427      \\
      & Init + GraMag  & 0.9032     & 0.4538     & 0.8095      & 0.8534      \\
 S013 &                &            &            &             &             \\
      & Init           & 0.8451     & 0.6146     & 0.7539      & 1.0551      \\
      & Init + GraMag  & 0.8501     & 0.5377     & 0.7363      & 0.9299      \\
 S014 &                &            &            &             &             \\
      & Init           & 0.8389     & 0.6730     & 0.8089      & 0.9837      \\
      & Init + GraMag  & 0.8410     & 0.5532     & 0.7868      & 0.7996      \\
 S019 &                &            &            &             &             \\
      & Init           & 0.8920     & 0.4798     & 0.8356      & 0.9672      \\
      & Init + GraMag  & 0.8794     & 0.3639     & 0.8081      & 0.7359      \\
\bottomrule
\end{tabular}
\label{tab:table2}
\end{table}

\section{Discussion}
\label{sec:Discussion}
Functional and anatomical MRI studies at the mesoscale ($< 1$ mm isotropic) require accurate and precise definitions of the GM ribbon. Creating such definitions is currently a challenging task since sub-millimeter UHF data bring non-brain structures like blood vessels and dura mater into sharper focus. As a result, segmentation algorithms that have been benchmarked at lower resolution data might falsely label part of these structures as GM. Here we presented the GraMag method to correct many such mislabeled non-brain voxels efficiently and semi-automatically. The method was based on theoretical expectations of how 3D brain data is to be represented in 2D histograms. These expectations imply that brain and non-brain tissue should become separable in 2D histogram representations that are based on gradient magnitude and intensity. We validated these expectations by implementing the suggested method in an openly available software package and by quantifying its added benefit using two new high-resolution validation data sets. We found that, in general, our suggested method offered an improvement compared to initial GM segmentations. However, we found some differences in the degree of improvement with respect to the (i) type of data and (ii) the algorithm used for initial segmentation. We will discuss these influences in turn.

First, we found that the improvements were slightly larger and more consistent across subjects for the MPRAGE than for the MP2RAGE data set. This might be explained by the fact that the MPRAGE data conformed more to our theoretical expectations than the MP2RAGE data set. Especially, we found GM values in the MP2RAGE uni image to be less focused on one particular area of the 2D histogram (Figure~\ref{fig:S07_Fig}) than the MPRAGE division image. This might result from differences in myelination level across cortical areas and depth \parencite{Sereno2013, Dick2012, DeMartino2015myelin}, which the MP2RAGE uni image might pick up more than MPRAGE division image \parencite{Marques2013}.

Second, we observed that the performance of the initial segmentation algorithm had an influence on how much we could further improve the GM segmentation. If performance of the initial segmentation algorithm was already relatively high, the improvement obtained with our methods tended to be smaller. Differences in initial segmentation performance might be explained by whether the algorithm has been benchmarked on this particular type of data. We assume FSL FAST and CBS tools to have been benchmarked on MPRAGE and MP2RAGE data respectively, which would explain their relative high performance for these data types.

Importantly, our goal here was to aid already existing segmentation pipelines to deal with UHF sub-millimeter resolution data, not to replace those pipelines. Instead, the method presented here should be considered as an alternative to a large amount of manual slice-by-slice polishing of segmentations and thus as a time-saver. Manually correcting segmentation labels is very time-consuming and can quickly become unreliable. In contrast, our method greatly reduces the time required for manual polishing because it offers an efficient 2D summary and is more reliable because it is semi-automatic. Although the method presented here does not entirely eliminate the need for manual corrections, we estimated that for a whole brain cortical ribbon segmentation it saves on average 7.5 hours of manual work per subject (for details on this estimation see Section \ref{sec:S1_Appendix} in the Supplementary Material).

Our theoretical expectations implied that the methods presented here require high-resolution data ($<$ 1 mm). This requirement was unfortunately not met by most available segmentation validation data sets. Simulated phantom ('BrainWeb') data \parencite{Collins1998} are available at 1 mm and thus fell short of the resolution required for our purposes. Although an updated data set ('updated BrainWeb'; \cite{AubertBroche2006a,AubertBroche2006b}) is available at higher resolution, the simulations in this data set were based on initial 3T MRI acquisitions. As a consequence, the updated BrainWeb data revealed considerably less bright-vessel and dura-mater voxels than 7~T data usually does, and it was not suitable to validate our methods.

These considerations led us to create our own high-resolution segmentation validation data sets for which we established the 'ground truth' via manually-guided expert segmentation. While expert segmentations have well-known drawbacks \parencite{Despotovic2015, Valverde2015}, they also have important advantages compared to alternative methods of establishing the ground truth, such as simulated phantom data. In particular, creating a validation data set based on empirical data and expert segmentations allowed us to benchmark our methods under conditions where image intensities fell into the expected range. Being aware of the problems with expert segmentations, we alleviate concerns about the quality of our expert judgment and consequently the validity of the results presented here by taking the following measures. First, the final ground truth segmentations were inspected by two additional experts. Second, we make the data sets and corresponding ground truth segmentations as well as our processing scripts available. This will allow other researchers to come up with their own judgment of the quality of the ground truth segmentations and validation data. In case changes to the ground truth are suggested and implemented, quantification could be re-run using our openly accessible work flow. 

The 2D histogram method presented here is, in principle, capable of generating its own exhaustive tissue-type classifications, i.e., it does not necessarily depend on existing segmentation pipelines to derive GM and WM labels. While we expect the 2D histogram method to give no advantage over existing, fully-automated segmentation algorithms under standard conditions, the histogram method will compare well in cases where standard algorithms fail. Importantly, the 2D histogram method used here does not assume the data to conform to any atlas or template shape. Therefore, it is suitable also for acquisitions with only partial coverage and surface coils, or for specific populations like infant or even dolphin brains (see Figure~\ref{fig:S4_Fig}).

Using histogram-based methods would be more attractive if the process of specifying transfer functions was fully automatic. We note that there is no principled obstacle to doing this. Indeed, information-theoretic measures have been suggested \parencite{Ip2012} that would make the normalized graph-cut application fully automatic, given the specification of an appropriate stopping criterion. The transfer functions (i.e. the circles and arcs applied to our 2D histograms) that we observed for the different brain tissue types were stable across subjects and conformed to expected, ideal shapes. This would allow to define probabilistic templates in the histogram space and transform the methods proposed here to a fully automatic exhaustive tissue-type classifications.

In the present work we have restricted ourselves to inputs of single 3D volumes. However, MRI can provide a multitude of informative images that weight different tissue properties to generate distinct image contrast. An obvious extension therefore is to combine information from several 3D volumes, where each volume contributes different contrast and information. Recently, a principled way to combine any number of MRI acquisitions has been suggested using the compositional data framework \parencite{Gulban2018c}. Combining the suggested method with the tools presented here could yield additional benefits. For example, in accordance with our theoretical expectation, the GraMag method identified and removed blood vessels and dura mater tissue. However, it often failed to sufficiently exclude connected tissue of the sagittal sinus because of similar intensity values and spatial proximity to GM. 
Given an appropriate contrast image that highlights the difference between GM and connected tissue, these structure should become separable. Naturally, performance of this method will depend on the specific choice of contrasts and whether these contrasts maximize the compositional difference between brain and non-brain tissue. Yet it can be envisioned that by selecting appropriate contrast images such a method could be used to single out targeted cortical or subcortical structures based on their compositional properties.

We understand our method as a secondary, more fine-grained brain extraction. When performing the initial brain extraction or tissue class segmentation, the user can often set parameters of the masking to be either more restrictive (at the risk of excluding brain tissue) or more liberal (at the risk of including a lot of non-brain tissue). We assume that, faced with this trade-off, users will usually lean to the liberal choice of parameters to avoid that relevant brain tissue is excluded. In such cases, we suggest our methods will prove useful. Our methods go beyond simply choosing more restrictive parameters because they focus on information that is relevant to excluding vessels, dura mater and connective tissue (Figure~\ref{fig:Fig1}D).

Our comparisons were limited to segmentations obtained from FSL, SPM and CBS tools. While several MRI studies at the mesoscale have used alternative ways of establishing tissue class segmentations \parencite{Fischl2004, Goebel2006}, we decided to limit our comparison to openly available algorithms. Furthermore, the resolution of our validation data exceeded the recommended input range for FreeSurfer (1 mm to 0.75 mm isotropic).

As is to be expected, we found our method to be impacted by the CNR of the input data (Figure~\ref{fig:S2_Fig}). In particular, additional noise caused the 2D histogram representation to conform less to expected template shapes. However, we note that for images that were acquired with currently very common imaging parameters at UHF, we found our method to offer clear benefits in GM segmentations. Furthermore, in case acquisitions will be noisier than the ones tested here, additional processing steps like non-linear anisotropic smoothing \parencite{Weickert1998, Mirebeau2015} might be applied to mitigate noise issues (see Figure~\ref{fig:S3_Fig}).

By making our validation data sets publicly available, we hope to inspire further algorithmic testing and development. There is currently a lack of validation data for the performance of tissue-type classification of MRI data acquired at UHF with sub-millimeter resolution. By publishing our data, our code, and our work flow, we invite fellow scientists to benefit from our work but also to further contribute to it. The neuro-imaging community can use our data to test the performance of entirely new methods or modifications to existing segmentation algorithms. Contributions could be made in the form of additional high-resolution data, more ground truth segmentations and algorithmic improvement. Anticipating such algorithmic improvements, we envision a future where segmentation of volumetric images will become gradually less laborious despite the increasing resolution and volume of the data.

\clearpage
\section{Supplementary material}
\subsection{Time benefit estimation}
\label{sec:S1_Appendix}
To estimate the time saved by substituting manual correction with Segmentator, we did the following calculation: Assuming that the objective of manually correcting mislabeled GM voxels is to reduce the number of false positives and to increase the number of true positives, we computed the number of false and true positives both before and after Segmentator intervention. We computed the difference in true positives and false positives before and after the application of segmentator and subtracted the true positive difference from the false positive difference. The resulting number is assumed to indicate the number of voxels which would have to be subtracted in the process of manually correcting all the voxels without using Segmentator. For the MRI data presented here, this number amounted to around 200000 voxels to be corrected (out of a total number of 1100000 voxels in the cortical ribbon). On average 35000 out of those 200000 voxels could be corrected using Segmentator. Assuming that a trained operator can manually correct one voxel per second, on average, this amounts to 7.5 hours of manual work that can be substituted with 10 minutes of Segmentator usage for the whole brain GM ribbon segmentation at 0.7 mm isotropic resolution. The time that can potentially be saved by using Segmentator will scale with the total number of GM voxels - it will be higher for high resolution acquisition (more voxels) and lower at low resolution (less voxels). The script used for our estimation is available at \cite{segmentator_processing_scripts}.

\clearpage
\subsection{Supplementary figures}
\beginsupplement

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/supp_deriche_gradient_magnitude.eps}
\caption{Appropriate kernel width approximates lower resolution. Intensity (left) and gradient magnitude (right) images are shown for T1w MRI data of a human brain (sagittal slice) that was either acquired at 0.7 mm isotropic (top) or at 0.25 mm isotropic \parencite{Lusebrink2017, 250micron_data} (bottom). By choosing an appropriate kernel width for the very high resolution image (here alpha = 1), the gradient magnitude image can be approximated to the lower resolution image, thus making it possible to use the gradient magnitude method also for very high resolutions.}
\label{fig:S1_Fig}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/supp_gramag_histograms_with_noise.png}
\caption{Impact of additional noise. Shown are intensity images (top row), gradient magnitude images (middle row) and 2D histograms (bottom row) for a T1w-divided-PDw MRI ratio image without any additional noise (left) and after applying a moderate (middle) and high (right column) amount of additive Gaussian noise with two levels of constant standard deviation of the distribution. The moderate noise ($\sigma=25$) is 16\% and high noise ($\sigma=50$) is 32\% calculated relative to the mean cortical GM intensity. Noise causes structures in the 2D histogram that are initially well-defined to spread outward and, at very high noise levels, to lose shape. Images show the transverse slice of an exemplary subject (sub-02).}
\label{fig:S2_Fig}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/supp_gramag_denoising_slices_and_histograms.png}
\caption{Noisy images can be denoised using non-linear anisotropic smoothing. Shown are intensity images (top row), gradient magnitude images (middle row) and 2D histograms (bottom row) for a T1w-divided-PDw MRI ratio image without any additional noise (left), after applying a high amount of noise (see Figure~\ref{fig:S2_Fig} for additional details) (middle), and after smoothing the noise-affected image (right column). As previously seen, noise causes structures in the 2D histogram to spread outward and to lose shape. This process can be reversed and noise-affected images can be recovered if a non-linear anisotropic smoothing filter (see \cite{Weickert1998}) is applied. With smoothing, structures become more confined to the expected regions and well-defined shapes are regained. Images show the transverse slice of an exemplary subject (sub-02).}
\label{fig:S3_Fig}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/supp_specific_cases.png}
\caption{Application of GraMag method to extra-ordinary MR images. Shown are several examples of the variety of existing volumetric datasets for which our method appears useful. Every column represents different images: the brain of a bottle-nose dolphin \parencite{Toro2014} (left), the occipital lobe of a human brain with 100 micron resolution \parencite{Amunts2013} (middle) and a human motor cortex acquired with small partial coverage (T1w EPI) with anisotropic resolution \parencite{Huber2017} (right). For every image we show a slice (top row), selected voxels in the 2D histogram (middle row) and selected voxels overlaid on the slice (bottom row). These images do not contain large intensity inhomogeneities. Therefore, no bias-field correction was performed. Mild non-linear anisotropic diffusion-based smoothing was applied to enhance CNR.}
\label{fig:S4_Fig}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/figure_S5.eps}
\caption{Flowchart diagram MPRAGE pipeline. This diagram provides a detailed overview of all the inputs, processing steps and outputs for MPRAGE pipeline. Rectangular shapes represent processing steps, rhombic shapes represent input or outputs and cylindrical shapes represent input or output locations.}
\label{fig:S5_Fig}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/figure_S6.eps}
\caption{Flowchart diagram MP2RAGE pipeline. This diagram provides a detailed overview of all the inputs, processing steps and outputs for MP2RAGE pipeline. Rectangular shapes represent processing steps, rhombic shapes represent input or outputs and cylindrical shapes represent input or output locations.}
\label{fig:S06_Fig}
\end{figure}

\begin{figure}[htbp!]
\centering
\includegraphics[width=\textwidth]{figures/chapter_02_SI/figure_1b.png}
\caption{2D histogram representation for MRI image of a human brain. The intensity \textbf{(A)} and gradient magnitude \textbf{(B)} values of a T1w-divided-by-PDw MRI image (MP2RAGE, 0.7 mm isotropic resolution) are represented in a 2D histogram \textbf{(C)}. Darker regions in the histogram indicate that many voxels are characterized by this particular combination of image intensity and gradient magnitude. The 2D histogram displays a characteristic pattern with tissue types occupying particular areas of the histogram \textbf{(D)}. Voxels containing CSF, dura mater or blood vessels (black dashed lines and arrows) cover different regions of the histogram than voxels containing WM and GM (red dashed lines). As a result, brain tissue becomes separable from non-brain tissue.}
\label{fig:S07_Fig}
\end{figure}

\clearpage
\subsection{Supplementary tables}

\begin{table}[htb!]
\centering
\caption{Availability of validation data and code. Validation data and scripts as well as segmentation software are all openly accessible by following the corresponding links for their repositories.}
\begin{tabular}{ll}
\\
\toprule
What? & Where? \\
\midrule
data & \url{https://zenodo.org/record/1206163}\\
scripts & \url{https://zenodo.org/record/1219231}\\
software & \url{https://zenodo.org/record/1220388}\\
\bottomrule
\end{tabular}
\label{tab:availability}
\end{table}

\clearpage
\section{Acknowledgments}
We would like to express our appreciation for the comments and suggestions of the reviewers which helped to improve the manuscript. We would also like to thank Thomas Emmerling for his guidance and advise on software implementation as well as Nikolaus Weiskopf, Rainer Goebel and Christophe Lenglet for valuable discussions of our early ideas.

\stopsupplement
\clearpage
\printbibliography[heading=subbibnumbered, title={References}]