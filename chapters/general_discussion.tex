\chapter{Chapter 5 - General discussion}
\lipsum[1-2]

\section{Grand overview}
\blindmathpaper

(Michelle)
The studies discussed in this thesis addressed two main research questions. First, how is the spectral content of natural sounds represented in our brain? Second, what mechanisms underlie the transition of a tonotopic sound image into a more abstract, behaviourally relevant sound representation? These questions were investigated by examining neuronal population frequency tuning based on fMRI responses to natural sounds. While each specific result was discussed in the separate chapters, the present discussion aims at integrating the findings across chapters, and at providing a more general framework. Specifically, a parcelation of the human auditory cortex based on its spectral tuning properties is proposed, and neuronal mechanisms underlying the formation of sound categories based on sensory sound representations are suggested.

(Mario)
The objective of this thesis was to present interdisciplinary research guided by theory originating from computational neuroscience and constrained by observations obtained from fMRI. Within this larger objective, the first part of the thesis was dedicated to theory testing in the context of the neuroscience of vision while the second part was dedicated to theory building in order to further our understanding of the relationship between structure and function. In what follows the results of each part are summarized. Subsequently, I will examine whether the goals set forth in the introduction were met, relate the approaches presented in this thesis to computational neuroimaging, and discuss potential future research directions.

(My own)
The goal of this thesis was to leverage the increase in signal afforded by higher field strength and sensitive surface coils to study conscious perception in humans at a new level of spatial detail.


\section{Group and data size}
The prospects for conducting a reproducible fMRI study are frighteningly bleak. There is a daunting gap between the amount of scanning hours that would theoretically be required to run a sufficiently powered study and the amount of hours that one can practically afford. Since the price of a single scanning hour of 7 Tesla fMRI is currently in the order of several hundred Euros, many researchers content themselves with 20 to 40 scanning hours per study. In addition to monetary constraints, other restrictions to many subject studies exist. For example, automatic segmentation algorithms yield results that are do not meet the quality demands of a sub-millimeter study. Consequently and tissue class segmentations become a bottleneck that hamper the 

https://www.overleaf.com/project/5c3651510a272905f017f291As pointed out in "Scanning the Horizon” (insert ref Poldrack)
Then you happen to read "Scanning the Horizon” which points out that a study with only 20 subjects is not even sufficiently powered to find the activation expected from a coarse comparison of motor activity to rest, much less to find the subtle signature of a complex cognitive process.

The likelihood of such a study identifying a true positive result if it exists is very low, and the likelihood of any positive results being false is high (as outlined by Button et al, 2013), even if the study was fully pre-registered and there is no p-hacking.  In the language of clinical trials, this study is futile, in the sense that it is highly unlikely to achieve its aims. In fact, such a study is arguably unethical, since the (however miniscule) risks of participating in the study are not offset by any potential benefit to the subject or to society. 

In all studies presented in this thesis we have followed an approach common to visual neuroscience. Each study reported the results of a few individuals only. However, those individuals were studied in great detail and we acquired many hours of scanning for every individual (often more than 4 hours of MRI data). Consistent with this approach, we did not employ and report standard group statistics. Instead, we showed single-subject results.

This approach prioritizes data quality over data quantity (insert reference Kolossa and Bruno, )
discuss measurement error (high) vs sampling error (low)

benefited from two factors:
1) sufficient signal in visual cortex (Wandell)
2) basic sensory/motor systems (where the variance between individuals is expected to be relatively low)

If they are consistent enough across the individuals then this might be enough to convince reviewers, though the farther you get from basic sensory/motor systems (where the variance between individuals is expected to be relatively low) the harder it will be to convince them. It is essential to keep in mind that this kind of analysis does not allow one to generalize beyond the sample of individuals who were included in the study, so any resulting papers will be necessarily limited in the conclusions they can draw. 

More data for few participants rather than little data for many participants.
Think like a visual scientist (Russ poldrack):
http://www.russpoldrack.org/2018/04/how-can-one-do-reproducible-science.html




\section{Implications for theory of brain function and perception}
The present work can be located in the domain of empirical science. Which constrains does the current work offer for theories of brain function and perception? 

Discuss motion quartet in the light of predictive processing.
- Refer to article by Hohwy and discuss bistable stimuli, like Motion quartet, in analogy to Hohwy's discussion of binocular rivalry
- Refer to article by Brascamp et al., Multistable Perception and the Role of Frontoparietal Cortex in Perceptual Inference


\section{Future directions}
The more appropriate title for this section would be "What I tried to do but did not manage".

- Develop the idea that what would be interesting to look at are different laminar contributions within a column. Acknowledge that this was not yet feasible. But present work is a step in the right direction and a necessary step on the way.
